第一部分 概述
一、交易型系统设计原则
    1、高并发原则
       (1) 无状态
       (2) 拆分: 业务、功能、数据库
       (3) 服务化 : 服务注册，负载均衡
       (4) 消息队列
       (5) 数据异构
       (6) 缓存 : 对于大型网站，可能会涉及多级缓存
       cc

    2、高可用原则
       (1) 降级
       (2) 限流： 防止恶意请求流量，恶意攻击
       (3) 切流量：机房挂了，需要切流量
       (4) 可回滚：

    3、业务设计原 则

二、负载均衡与反向代理
    HTTP负载均衡，也就是我们通常所有“七层负载均衡”,工作在第七层“应用层”(ngx_http_upstream_module)

    Nginx具有TCP负载均衡的功能 (ngx_stream_upstream_module)
    TCP负载均衡， 就是我们通常所说的“四层负载均衡”,工作在“网络层”和“传输层”
    1、TCP负载均衡的配置方式: 使用了一个新的stream模块来实现TCP负载均衡,允许我们配置一组监听TCP连接的服务,允许你配置多个服务的TCP连接，通过在upstream的server组中配置proxy_pass指令
        stream（和http等同级）
        stream {
            server {
                listen 1034;
                proxy_pass app;
            }
            upstream app {
                server 192.168.0.3:1034;
                server 192.168.0.4:1034;
                server 192.168.0.6:1034;
            }
        }
    2、TCP负载均衡原理 : 当Nginx从监听端口收到一个新的客户端链接时，立刻执行路由调度算法，获得指定需要连接的服务IP，然后创建一个新的上游连接，连接到指定服务器。
    3、服务健壮性监控 : TCP负载均衡模块支持内置健壮性检测，一台上游服务器如果拒绝TCP连接超过proxy_connect_timeout配置的时间，将会被认为已经失效。在这种情况下，Nginx立刻尝试连接upstream组内的另一台正常的服务器
    4、可以通过OpenResty实现更智能的负载均衡
    5、失败重试：upstream server 和 proxy_pass
    6、健康检查：nginx_upstream_check_module支持TCP和Http心跳检查
    7、域名上游服务器
       upstream backend {
            server c0.3.cn
            server c1.3.cn
       }
       备份上游服务器
       upstream backend {
           server 192.168.61.1:9080 weight = 1;
           server 192.168.61.1:9090 weight = 2 backup;
       }
       不可用上游服务器
       upstream backend {
          server 192.168.61.1:9080 weight = 1;
          server 192.168.61.1:9090 weight = 2 down;
       }

    8、Nginx与上游服务器长连接 ： keepalive 每个worker进程与上游服务器可缓存的空闲连接的最大数量。超出这个数量时，最近最少使用的连接将关闭。
       upstream backend {
            server 192.168.61.1: 9080 weight =1;
            server 192.168.61.1: 9090 weight =2 backip;
            keepalive 100;
       }
       location / {
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            proxy_pass http://backend;
       }

    9、Nginx（动态负载均衡）：使用nginx-stream-upsync-module

三、隔离术
    1、线程隔离： 线程隔离主要是指线程池隔离，会把请求分类，然后交给不同的线程池处理。
    2、进程隔离： 系统拆分
    3、集群隔离：
    4、机房隔离：每个机房的服务都有自己的服务分组，本机房的服务应该只调用本机房服务，不进行垮机房调用。
    5、读写隔离：
    6、动静隔离：静态文件和动态文件分离
    7、爬虫隔离：
    8、使用Hystrix（熔断器）实现服务隔离
    9、基于Servlet3实现请求隔离 : Servlet3请求异步化(注Tomcat6和Tomcat7的区别 )

四、限流详解（抢购和抢票）
    常见的限流： 限制总并发数（数据库连接池）、限制瞬时并发数（Nginx的limit_conn模块），限制平均速率（Nginx的limit_req模块），以及限制远程接口调用速率，
    限制MQ的消费速率。
    一、限流方法： 令牌桶，漏桶
        1 令牌桶
          假设限制2r/s,则按照500毫秒的固定速率往桶中添加令牌
          桶中最多存放b个令牌，当桶满时，新添加的令牌被丢弃
          当一个请求过来，会从桶中删除n个令牌，如果桶中大于n个令牌，接着数据包被发送到网络，如果桶中小于n个令牌，请求将被限流

        2 漏桶
          一个固定容量的漏桶，按照常量固定速率流出水滴
          如果桶是空的，则不需流出水滴
          可以以任意速率流入水滴到漏桶
          如果流入水滴超出了桶的容量，则流入的水滴丢弃

    二、应用级限流
        1、限流总并发/连接/请求数 （TPS/QPS）
        2、限流总资源数
        3、限流某个接口的总并发/请求数 ：使用AtomicLong 或者 Semaphore
           try{
                if(atomic.incrementAndGet() > 限流数){

                }
           } finally{
                atomic.decrementAndGet();
           }
        4、限流某个接口的每秒请求数
        5、平滑限流某个接口的请求数 ：Guava RateLimiter提供的令牌桶算法可用于平滑突发限流和平滑预热限流
        6、分布式限流：将限流服务做成原子化，而解决方案可以使用Redis + Lua 或 Nginx + Lua

    三、接入层限流
        1、负载均衡、非法请求过滤、请求聚合、缓存、降级、限流、A/B测试、服务质量监控等。
           Nginx接入层限流可以使用Nginx自带的模块： 还可以使用OpenResty提供的Lua限流模块

    四、节流 : 特定时间窗口内对重复的相同事件最多处理一次，或者想限制多个连续相同事件最小执行时间间隔。

五： 降级 目的是保证核心服务可用
     1、自动降级： 超时降级、统计失败降级、故障降级、限流降级
     2、人工降级： 手动停用一些服务

六、超时与重试机制
    1、如果应用不设置超时，可能会导致请求响应慢，慢请求积累导致连锁反应，并且设置合理的重试机制
    一、代理层超时与重试
        1、Nginx：
        客户端超时设置： 读取请求头超时时间，读取请求体超时时间，发送响应超时时间，长连接超时时间
        DNS解析超时设置： Nginx使用域名时，需要设置DNS解析超时时间
        代理超时设置：
            网络连接：
                proxy_connect_timeout time: 从后端/上游服务器建立连接的超时时间，默认60s
                proxy_read_timeout time: 设置从后端/上游服务器读取响应的超时时间，默认60s
                proxy_send_timeout time: 设置从后端/上游服务器发送请求的超时时间，默认60s
            失败重试：
                proxy_next_upstream error
                proxy_next_upstream_tries number
                proxy_next_upstream_timeout time

     二、Web容器超时
            1、connectionTimeout: 配置与客户端建立连接的超时时间
            2、socket.soTimeout:从客户端读取请求数据的超时时间
            3、asyncTimeout:Servlet3异步请求时间
            4、文件上传的超时时间
            5、keepAliveTimeout和maxKeepAliveRequest：长连接超时时间

     三、数据库客户端超时

七、回滚机制 ： 事务回滚、部署版本回滚

第二部分 高并发
第9章 应用级缓存
    1、缓存命中率: 从缓存中读取数据的次数与总读取次数的比率，命中率越高越好
    2、缓存回收策略:
        1、基于空间指缓存设置了存储空间，如设置10MB，当达到存储空间上限是，按照一定的策略移除数据。
        2、基于时间 ： 存活期（缓存数据从创建开始直到到期的一个时间段）
                       空闲期（缓存数据多久没被访问后移除缓存的时间）
        3、java的软引用可以做缓存对象
        4、FIFO：先进先出
           LRU：最近最少使用
           LFU：最不常使用

    3  堆缓存:   使用java堆内存来存储缓存对象.好处是不需要序列化，缺点占堆内存，一般比较热数据 Guava Cache
       堆外缓存: 缓存空间大，但需要序列化
       缓存磁盘
       分布式缓存

第10章
    1、http缓存
      1 服务器端响应的Last-Modified会在下次请求时，将If-Modified-Since请求头带到服务器进行文档是否修改的验证，如果没有修改则返回304，浏览器可以直接使用缓存内容
      2 Cache-Control:max-age和Expires用于决定浏览器端内容缓存多久
      3 Http/1.1 规范定义的Cache-Control优先级高于Http1.0
    2、HttpClient客户端缓存
    3、Nginx Http缓存
        1、浏览器发起请求，首先到Nginx，Nginx根据URL在Nginx本地查找是否有代理层本地缓存
        2、Nginx没有找到本地缓存，则访问后端获取最新的文档，并放入Nginx本地缓存，返回200
        3、Nginx找到本地缓存，并没有过期，则返回304
    4、缓存Value要进行压缩

第11章
    1、数据库连接池: 通过复用TCP连接来减少创建和释放连接时间来提升性能
    2、HttpClient连接池:
      可以在使用HttpClient的时候，使用连接池
      如果不采用连接池，每次连接发起Http请求的时候都会重新建立TCP连接(经历3次握手)，用完就会关闭连接(4次挥手)，如果采用连接池则减少了这部分时间损耗
      HttpConnectionManager连接池管理类